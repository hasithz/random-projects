# -*- coding: utf-8 -*-
"""Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1exjkKpYTsd2Jji_yZcWUjtDllGgg5Zl1
"""

from google.colab import drive
drive.mount('/gdrive')
drive.mount("/gdrive", force_remount=True)

import numpy as np
import os

data=np.load('/gdrive/MyDrive/Project/new_data.npy')
target=np.load('/gdrive/MyDrive/Project/new_target.npy')

print(len(target))
print(target)

from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten
from keras.layers import Conv2D,MaxPooling2D
from tensorflow.keras.utils import to_categorical

model=Sequential()

model.add(Conv2D(256,(3,3),input_shape=data.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(3,3)))
#The first CNN layer followed by Relu and MaxPooling layers

model.add(Conv2D(128,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The second CNN layer followed by Relu and MaxPooling layers

model.add(Flatten())
#Flatten layer to stack the output convolutions from second convolution layer
model.add(Dense(64,activation='relu'))
#Dense layer of 64 neurons
model.add(Dense(7,activation='softmax'))
#The Final layer with two outputs for two categories

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
# model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()

from sklearn.model_selection import train_test_split

train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)

print(train_data.shape[1:])
print(train_target.shape[1:])
print(test_data.shape[1:])
print(test_target.shape[1:])
print(len(data))
print (len(target))

from keras.callbacks import ModelCheckpoint
import tensorflow
checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')

print (train_data.shape)
print (train_target.shape)

tensorflow.keras.utils.to_categorical(train_target, num_classes=None, dtype='float32')
history=model.fit(train_data,train_target,epochs=2000,callbacks=[checkpoint],validation_split=0.1)

